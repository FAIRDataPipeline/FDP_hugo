<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>FAIRDataPipeline</title>
    <link>https://www.fairdatapipeline.org/docs/API/Java/</link>
    <description>Recent content on FAIRDataPipeline</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <atom:link href="https://www.fairdatapipeline.org/docs/API/Java/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/coderun/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/coderun/</guid>
      <description>javaDataPipeline Coderun # The main class used to interface with the FAIR DataPipeline in Java, is the Coderun class.
Users should initialise the Coderun instance using a try-with-resources block or ensure that .close() is explicitly called upon finishing.
The Coderun constructor needs a Path to the config.yaml, a Path to the script.sh, and the registry authentication token.
The user then would access the input data product(s) using coderun.get_dp_for_read(dataproduct_name) and output data product(s) using coderun.</description>
    </item>
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/issues/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/issues/</guid>
      <description>javaDataPipeline Issues # Issues can be attached to Object_components, as well as to the Submission Script, Config File, and Code Repo.
Issues can be created and then linked to the elements that they apply to, or they can be raised directly on the element it refers to.
Here is an example of the creation then linking of an Issue to components, Script, and Code Repo:
try (Coderun coderun = new Coderun(configPath, scriptPath, token)) { Data_product_read dp = coderun.</description>
    </item>
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/parameters/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/parameters/</guid>
      <description>Parameters # Below are examples of all the parameter types that can be written to and read from the FAIR Data Pipeline TOML parameter file format. These TOML parameter files are described on the API page.
Samples
samples = ImmutableSamples.builder().addSamples(1, 2, 3).rng(rng).build(); object_component.writeSamples(samples); Distribution (Gamma)
distribution = ImmutableDistribution.builder() .internalShape(1) .internalScale(2) .internalType(DistributionType.gamma) .rng(rng) .build(); object_component.writeDistribution(distribution); Categorical Distribution
MinMax firstMinMax = ImmutableMinMax.builder() .isLowerInclusive(true) .isUpperInclusive(true) .lowerBoundary(0) .upperBoundary(4) .build(); MinMax secondMinMax = ImmutableMinMax.builder() .</description>
    </item>
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/hdf5/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/hdf5/</guid>
      <description>HDF5 # HDF files are not supported in the current version of the Java FAIR Data Pipeline API.</description>
    </item>
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/run/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/run/</guid>
      <description>Running your code # Below is a brief explanation how to make use of the Java FAIRDataPipeline library and actually getting your code to run from the FAIR CLI command line interface. The actual command to run your Java code is given in the script: line in the config.yaml. In my case I run the Java code using gradle run --args &amp;quot;${{CONFIG_DIR}}&amp;quot;. You&amp;rsquo;ll have to change this if you don&amp;rsquo;t use gradle.</description>
    </item>
    <item>
      <title></title>
      <link>https://www.fairdatapipeline.org/docs/API/Java/debug/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://www.fairdatapipeline.org/docs/API/Java/debug/</guid>
      <description>Debugging / troubleshooting # Logger # The javaDataPipeline library uses SLF4J (Simple Logging Facade for Java).
You can either use this with the SLF4J simple logger, or it can bind to your own favourite logging framework. In order to set the default simple logger to more verbose logging:
add the org.slf4j:slf4j-simple dependency set the log level: System.setProperty(org.slf4j.impl.SimpleLogger.DEFAULT_LOG_LEVEL_KEY, &amp;quot;TRACE&amp;quot;);
Running manually # Instead of running:
fair run src/main/resources/config.yaml You can call fair run and your actual java code separately:</description>
    </item>
  </channel>
</rss>
