---
weight: 40
title: "Full working example (with descriptions of Data Pipeline API functionality)"
---

<span style="font-size:12pt; color:red">Note that this is a living document and the following is subject to change. </span>

# Full working example (with Data Pipeline API functionality)

This page gives a full working example of the **user written** *config.yaml* file alongside the working config file generated by `FAIR run`. Note that **the Data Pipeline API will take the working config file as an input**.

The following example downloads some data from outside the pipeline, does some processing in R (for example), and records the original file and the resultant data product into the pipeline.

In this simple example, the user should run the following from the terminal:

```bash
fair pull config.yaml
fair run config.yaml
fair push config.yaml
```

These functions require a *config.yaml* file to be supplied by the user. This file should specify various metadata associated with the code run, including where external objects comes from and the aliases that will be used in the submission script, data objects to be read and written, and the submission scipt location.

## User written *config.yaml*

```yaml
run_metadata:
  description: Register a file in the pipeline
  local_data_registry_url: https://localhost:8000/api/
  remote_data_registry_url: https://data.scrc.uk/api/
  default_input_namespace: SCRC
  default_output_namespace: soniamitchell
  write_data_store: /Users/SoniaM/datastore/
  local_repo: /Users/Soniam/Desktop/git/SCRC/SCRCdata
  script: |- 
    R -f inst/SCRC/scotgov_management/submission_script.R ${{CLI.CONFIG_DIR}}
register:
- external_object: records/SARS-CoV-2/scotland/cases-and-management
  source_name: Scottish Government Open Data Repository
  source_abbreviation: Scottish Government Open Data Repository
  source_website: https://statistics.gov.scot/
  root_name: Scottish Government Open Data Repository database
  root: https://statistics.gov.scot/sparql.csv?query=
  path: |
    PREFIX qb: <http://purl.org/linked-data/cube#>
    PREFIX data: <http://statistics.gov.scot/data/>
    PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
    PREFIX mp: <http://statistics.gov.scot/def/measure-properties/>
    PREFIX dim: <http://purl.org/linked-data/sdmx/2009/dimension#>
    PREFIX sdim: <http://statistics.gov.scot/def/dimension/>
    PREFIX stat: <http://statistics.data.gov.uk/def/statistical-entity#>
    SELECT ?featurecode ?featurename ?date ?measure ?variable ?count
    WHERE {
      ?indicator qb:dataSet data:coronavirus-covid-19-management-information;
                  dim:refArea ?featurecode;
                  dim:refPeriod ?period;
                  sdim:variable ?varname;
                  qb:measureType ?type.
      {?indicator mp:count ?count.} UNION {?indicator mp:ratio ?count.}

      ?featurecode <http://publishmydata.com/def/ontology/foi/displayName> ?featurename.
      ?period rdfs:label ?date.
      ?varname rdfs:label ?variable.
      ?type rdfs:label ?measure.
    }
  title: Data associated with COVID-19
  description: The data provide past data around COVID-19 for the daily updates provided by the Scottish Government.
  unique_name: COVID-19 management information
  file_type: csv
  release_date: ${{CLI.DATETIME}}
  version: 0.${{CLI.DATE}}.0
  primary: True
  accessibility: open

write:
- data_product: records/SARS-CoV-2/scotland/cases-and-management/ambulance
  description: Ambulance data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/calls
  description: Calls data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/carehomes
  description: Care homes data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/hospital
  description: Hospital data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/mortality
  description: Mortality data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/nhsworkforce
  description: NHS workforce data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/schools
  description: Schools data
  version: 0.${{CLI.DATE}}.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/testing
  description: Testing data
  version: 0.${{CLI.DATE}}.0
```

## Working *config.yaml*

`fair run` should create a working *config.yaml* file, which is then read by the Data Pipeline API.

```yaml
run_metadata:
  description: Register a file in the pipeline
  local_data_registry_url: https://localhost:8000/api/
  remote_data_registry_url: https://data.scrc.uk/api/
  default_input_namespace: SCRC
  default_output_namespace: soniamitchell
  write_data_store: /Users/SoniaM/datastore/
  local_repo: /Users/Soniam/Desktop/git/SCRC/SCRCdata
  script: R -f inst/SCRC/scotgov_management/submission_script.R /Users/SoniaM/datastore/coderun/20210511-231444/
read:
- external_object: records/SARS-CoV-2/scotland/cases-and-management
  doi_or_unique_name: COVID-19 management information
  title: Data associated with COVID-19
  version: 0.20210414.0
write:
- data_product: records/SARS-CoV-2/scotland/cases-and-management/ambulance
  description: Ambulance data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/calls
  description: Calls data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/carehomes
  description: Care homes data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/hospital
  description: Hospital data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/mortality
  description: Mortality data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/nhsworkforce
  description: NHS workforce data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/schools
  description: Schools data
  version: 0.20210414.0
- data_product: records/SARS-CoV-2/scotland/cases-and-management/testing
  description: Testing data
  version: 0.20210414.0
```

## *submission_script.R*

A submission script should be supplied by the user, which in this case registers an external object, reads it in, and then writes it back to the pipeline as a data product component. In the above example, this script is located in *<local_repo>/inst/SCRC/scotgov_management/submission_script.R*.

```R
library(SCRCdataAPI)

# Open the connection to the local registry with a given config file
config <- file.path(Sys.getenv("FDP_CONFIG_DIR"), "config.yaml")
script <- file.path(Sys.getenv("FDP_CONFIG_DIR"), "script.sh")
handle <- initialise(config, script)

# Return location of file stored in the pipeline
input_path <- link_read(handle, "raw-mortality-data")

# Process raw data and write data product
data <- read.csv(input_path)
array <- some_processing(data) # e.g. data wrangling, running a model, etc.
index <- write_array(array, 
                     handle, 
                     data_product = "records/SARS-CoV-2/scotland/cases-and-management/mortality", 
                     component = "mortality_data",
                     dimension_names = list(location = rownames(array),
                                            date = colnames(array)))
issue_with_component(index,
                     handle,
                     issue = "this data is bad",
                     severity = 7)

finalise(handle)
```

### `initialise()`

- responsible for reading the working *config.yaml* file
- registers the working *config.yaml* file and submission script
- registers a CodeRun (since the CodeRun UUID should be referenced if `${{DPAPI.RUN_ID}}` is specified in a DataProduct name)
- returns a `handle` containing:
  - the working *config.yaml* file contents
  - the object id for this file
  - the object id for the submission script file

### `link_read()`

- responsible for returning the path of an external object in the local data store
- updates `handle` with file path (if not already present) and useful metadata
- returns file path

### `read_array()`

- responsible for reading the correct data product, which at this point has been downloaded from the remote data store by `fair pull`
- reads a specified version of the data
- updates `handle`

### `link_write()`

- returns a path to write external objects to
- updates `handle`

### `write_array()`

- responsible for writing an array as a component to an hdf5 file
- updates `handle`
  - if this is the first component to be written, update `handle` with storage location
  - if this is not the first component to be written, reference the storage location from the `handle`
  - if the component is already recorded in the handle, return the index of this handle reference invisibly
- writes component to the hdf5 file

### `issue_with_component()`

- **this is very much a work in progress**
- find the input or output reference (in the handle) that the issue is associated with
- note that issues can also be associated with scripts, etc. (I've not gone near this yet)
- record issue metadata in the handle
- NOTE that in the above example, `issue_with_component()` takes an `index` that references an object recorded in the handle, alternatively it may take a `dataproduct`, `component`, and `version` as identifiers
- NOTE that `issue_with_component()` is but one of a series of functions including `inssue_with_dataproduct()`, `issue_with_externalobject()`, and `issue_with_script()`; it might make more sense for you to write a generic `raise_issue()` function depending on language constraints

### `finalise()`

- renames any hdf5 files as *<hash>.h5*
- renames any data products (storage directory) if variables are present, *e.g.* for `human/outbreak/simulation_run-${{DPAPI.RUN_ID}}`, `${{DPAPI.RUN_ID}}` is replaced with the CodeRun UUID
- records metadata (*e.g.* location, components, various descriptions, issues) in the data registry
- records the code run in the data registry

## *submission_script.py*

Alternatively, the submission script may be written in Python.

```python
from data_pipeline_api.standard_api import StandardAPI

with StandardAPI.from_config("config.yaml") as api:
  data = read(api.link_read("records/SARS-CoV-2/scotland/cases-and-management"))
  data
  api.write_array("records/SARS-CoV-2/scotland/cases-and-management/mortality", "mortality_data", matrix)
  api.issue_with_component("records/SARS-CoV-2/scotland/cases-and-management/mortality", "mortality_data", "this data is bad", "7")
  api.finalise()
```

## *submission_script.jl*

Alternatively, the submission script may be written in Julia.

```julia
using DataPipeline

# Open the connection to the local registry with a given config file
handle = initialise("working-config.yaml", "script.sh") 

# Return location of file stored in the pipeline
input_path = link_read(handle)

# Process raw data and write data product
data = read_csv(input_path)
array = some_processing(data) # e.g. data wrangling, running a model, etc.
index = write_estimate(array, 
                       handle, 
                       data_product = "records/SARS-CoV-2/scotland/cases-and-management/mortality", 
                       component = "mortality_data")

issue_with_component(index,
                     handle,
                     issue = "this data is bad",
                     severity = 7)

finalise(handle)
```

## C++

## Java