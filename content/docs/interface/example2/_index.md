---
weight: 40
title: "Additional working examples"
---

<span style="font-size:12pt; color:red">Note that this is a living document and the following is subject to change.</span>

# Additional working examples

This page gives addition examples of the **user written** *config.yaml* file alongside the working config file generated by `FAIR run`. Note that **the Data Pipeline API will take the working config file as an input**.

These examples may include variables not mentioned on previous pages or cases that might rarely be encountered such as using aliases.

## Read data product, process, and write data product (with aliases)

### User written *config.yaml*

```yaml
run_metadata:
  description: A test model
  local_data_registry_url: https://localhost:8000/api/
  remote_data_registry_url: https://data.scrc.uk/api/
  default_input_namespace: SCRC
  default_output_namespace: soniamitchell
  write_data_store: /Users/SoniaM/datastore/
  local_repo: /Users/Soniam/Desktop/git/SCRC/SCRCdata
  script: |- 
    R -f inst/SCRC/scotgov_management/submission_script.R ${{CLI.CONFIG_DIR}}

read:
- data_product: human/population
  use:
    namespace: johnsmith
    data_product: scotland/human/population

write:
- data_product: human/outbreak-timeseries
  description: data product description
  use:
    data_product: scotland/human/outbreak-timeseries
- data_product: human/outbreak/simulation_run
  description: another data product description
  use:
    data_product: human/outbreak/simulation_run-${{DPAPI.RUN_ID}}
```

### Working *config.yaml*

`fair run` should create a working *config.yaml* file, which is read by the Data Pipeline API. In this example, the working *config.yaml* file is pretty much identical to the original *config.yaml* file, only `${{CLI.CONFIG_DIR}}` is replaced by the directory in which the working *config.yaml* file resides.

```yaml
run_metadata:
  description: A test model
  local_data_registry_url: https://localhost:8000/api/
  remote_data_registry_url: https://data.scrc.uk/api/
  default_input_namespace: SCRC
  default_output_namespace: soniamitchell
  write_data_store: /Users/SoniaM/datastore/
  local_repo: /Users/Soniam/Desktop/git/SCRC/SCRCdata
  latest_commit: 221bfe8b52bbfb3b2dbdc23037b7dd94b49aaa70
  remote_repo: https://github.com/ScottishCovidResponse/SCRCdata
  script: |- 
    R -f inst/SCRC/scotgov_management/submission_script.R /Users/SoniaM/datastore/coderun/20210511-231444/

read:
- data_product: human/population
  use:
    namespace: johnsmith
    data_product: scotland/human/population
    version: 0.1.0

write:
- data_product: human/outbreak-timeseries
  description: data product description
  use:
    data_product: scotland/human/outbreak-timeseries
    version: 0.1.0
    public: true
- data_product: human/outbreak/simulation_run
  description: another data product description
  use:
    data_product: human/outbreak/simulation_run-${{DPAPI.RUN_ID}}
    version: 0.1.0
    public: true
```

## Read then write a data product component

Now that the pipeline is populated, one of the simplest possible use cases is just to read in a value, calculate a new value from it, and write out the new value. Again, we need to write a *config.yaml* file:

### User written *config.yaml*

```yaml
run_metadata: 
  description: A simple example reading and writing data products
  default_input_namespace: SCRC
  local_repo: /Users/johnsmith/git/myproject
  script: | # addresses are relative to local_repo
    julia -f path/submission_script.jl ${{CLI.CONFIG_DIR}}

read:
- data_product: human/infection/SARS-CoV-2

write:
- data_product: human/infection/SARS-CoV-2/doubled
  component: doubled-infectious-period
```

### Working *config.yaml*

```yaml
...
```
